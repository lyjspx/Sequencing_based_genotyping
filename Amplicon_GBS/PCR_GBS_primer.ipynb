{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"hrsw1.v36.rawByJason.vcf\") as vcffile:\n",
    "    vcflines = vcffile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['##fileformat=VCFv4.0\\n',\n",
       " '##Tassel=<ID=GenotypeTable,Version=5,Description=\"Reference allele is not known. The major allele was used as reference allele\">\\n',\n",
       " '##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\\n',\n",
       " '##FORMAT=<ID=AD,Number=.,Type=Integer,Description=\"Allelic depths for the reference and alternate alleles in the order listed\">\\n',\n",
       " '##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth (only filtered reads used for calling)\">\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcflines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variant_repo = {} #Each variant was assigned with a unique ID\n",
    "variant_repo_no_ID = {} \n",
    "ID = 0 #Assign an ID to each variant\n",
    "for line in vcflines:\n",
    "    if line[0] == \"#\":\n",
    "        pass\n",
    "    else:\n",
    "        variant = line.split(\"\\t\")\n",
    "        if variant[0] not in variant_repo:\n",
    "            variant_repo[variant[0]]=list()\n",
    "            variant_repo[variant[0]].append([ID,int(variant[1])])\n",
    "            variant_repo_no_ID[variant[0]]=set()\n",
    "            variant_repo_no_ID[variant[0]].add(int(variant[1]))\n",
    "        else:\n",
    "            variant_repo[variant[0]].append([ID,int(variant[1])])\n",
    "            variant_repo_no_ID[variant[0]].add(int(variant[1]))\n",
    "        ID=ID+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A\n",
      "1B\n",
      "1D\n",
      "3B\n",
      "5D\n",
      "3A\n",
      "5A\n",
      "5B\n",
      "7D\n",
      "7B\n",
      "7A\n",
      "3D\n",
      "2D\n",
      "2A\n",
      "2B\n",
      "4D\n",
      "4B\n",
      "4A\n",
      "6A\n",
      "6B\n",
      "6D\n"
     ]
    }
   ],
   "source": [
    "len(variant_repo)\n",
    "del variant_repo[\"UN\"]\n",
    "del variant_repo_no_ID[\"UN\"]\n",
    "for key in variant_repo:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Jan_17_2019 pull out some snp information for Jason, everything inside this cell is temporary\n",
    "queryList=[]\n",
    "with open(\"GT2.snps_Jan16_byJason\",\"r\") as inputf:\n",
    "    for line in inputf:\n",
    "        queryList.append(line.strip().split(\"\\t\"))\n",
    "for variant in queryList:\n",
    "    for each in variant_repo_no_ID[variant[0][1:]]:\n",
    "        if(abs(each-int(variant[1]))<200):\n",
    "            variant.append(each)\n",
    "with open(\"GT2.snps_Jan16_byJason_output\",\"w\") as outputf:\n",
    "    for variant in queryList:\n",
    "        outputf.write(\"\\t\".join(str(v) for v in variant)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2x3x4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####clean lines to trim off \\n\n",
    "#write into file\n",
    "# referenceSourcef = open(\"161010_Chinese_Spring_v1.0_pseudomolecules.fasta\",\"r\") \n",
    "# outputReferencef = open(\"reference_wheat.fasta\", \"w\")\n",
    "# readLine = referenceSourcef.readline()\n",
    "# outputReferencef.write(readLine)\n",
    "# readLine = referenceSourcef.readline()\n",
    "# while readLine:\n",
    "#     if readLine[0] == \">\":\n",
    "#         outputReferencef.write(\"\\n\" + readLine)\n",
    "#     else:\n",
    "#         outputReferencef.write(readLine.strip())\n",
    "#     readLine = referenceSourcef.readline()\n",
    "# referenceSourcef.close()\n",
    "# outputReferencef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"reference_wheat.fasta\",\"r\") as cleaned_reference:\n",
    "    reference_test = {}\n",
    "    currentLine = cleaned_reference.readline()\n",
    "    currentChr = \"\"\n",
    "    while currentLine:\n",
    "        if currentLine[0] == \">\":\n",
    "            reference_test[currentLine[4:6]] = \"\"\n",
    "            currentChr = currentLine[4:6]\n",
    "            currentLine = cleaned_reference.readline()\n",
    "        else:\n",
    "            reference_test[currentChr] = currentLine\n",
    "            currentLine = cleaned_reference.readline()\n",
    "del reference_test[\"Un\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_test[\"7B\"][577278600:].find(\"CTCTGAGTTTCATCAGTTTCACTTCTAAACGTGATATTTCTAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###PstI-MseI   PstI\n",
    "primer_pool = {}\n",
    "for chr in variant_repo:\n",
    "    for SNP in variant_repo[chr]:\n",
    "        uniqueID = SNP[0]\n",
    "        SNPposition = int(SNP[1])\n",
    "        hundredAhead = reference_test[chr][(SNPposition-200):SNPposition]\n",
    "        cuttingPos = hundredAhead.find(\"CTGCAG\")\n",
    "        if cuttingPos >= 16:\n",
    "            potentialPrimer = hundredAhead[(cuttingPos-16):cuttingPos]\n",
    "            #not reverse\n",
    "            reversePotentialPrimer = potentialPrimer\n",
    "            if reversePotentialPrimer not in primer_pool:\n",
    "                primer_pool[reversePotentialPrimer] = 1\n",
    "            else:\n",
    "                primer_pool[reversePotentialPrimer] = primer_pool[reversePotentialPrimer] + 1 \n",
    "\n",
    "###PstI-Mse MseI\n",
    "# primer2_pool = {}\n",
    "# for chr in variant_repo:\n",
    "#     for SNP in variant_repo[chr]:\n",
    "#         uniqueID = SNP[0]\n",
    "#         SNPposition = int(SNP[1])\n",
    "#         hundredAhead = reference_test[chr][SNPposition:(SNPposition+1000)]\n",
    "#         cuttingPos = hundredAhead.find(\"TTAA\")\n",
    "#         if cuttingPos >= 15:\n",
    "#             potentialPrimer = hundredAhead[(cuttingPos-15):cuttingPos]\n",
    "#             #not reverse\n",
    "#             reversePotentialPrimer = potentialPrimer\n",
    "#             if reversePotentialPrimer not in primer2_pool:\n",
    "#                 primer2_pool[reversePotentialPrimer] = 1\n",
    "#             else:\n",
    "#                 primer2_pool[reversePotentialPrimer] = primer2_pool[reversePotentialPrimer] + 1 \n",
    "\n",
    "#The below is attempting to search qualitified reverse primer \n",
    "#The above block is searching reverse primer nearby MseI site \n",
    "primer2_pool = {}\n",
    "for chr in variant_repo:\n",
    "    for SNP in variant_repo[chr]:\n",
    "        uniqueID = SNP[0]\n",
    "        SNPposition = int(SNP[1])\n",
    "        hundredAhead = reference_test[chr][SNPposition:(SNPposition+1000)]\n",
    "        cuttingPos = hundredAhead.find(\"TTAA\")\n",
    "        if cuttingPos >= 15 and cuttingPos <= 900:\n",
    "            searchInterval = hundredAhead[cuttingPos:(cuttingPos+200)] #define searching interval\n",
    "            potentialFragment = set()\n",
    "            for i in range(0,80,2):\n",
    "                potentialFragment.add(searchInterval[i:(i+25)])\n",
    "            for element in potentialFragment:\n",
    "                reversePotentialPrimer = element\n",
    "                if reversePotentialPrimer not in primer2_pool:\n",
    "                    primer2_pool[reversePotentialPrimer] = 1\n",
    "                else:\n",
    "                    primer2_pool[reversePotentialPrimer] = primer2_pool[reversePotentialPrimer] + 1 \n",
    "               \n",
    "                \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###MseI - PstI  MseI\n",
    "primer_pool = {}\n",
    "for chr in variant_repo:\n",
    "    for SNP in variant_repo[chr]:\n",
    "        uniqueID = SNP[0]\n",
    "        SNPposition = int(SNP[1])\n",
    "        hundredAhead = reference_test[chr][(SNPposition-1000):SNPposition]\n",
    "        cuttingPos = hundredAhead.find(\"TTAA\")\n",
    "        if cuttingPos >= 16:\n",
    "            potentialPrimer = hundredAhead[(cuttingPos-15):cuttingPos]\n",
    "            #not reverse\n",
    "            reversePotentialPrimer = potentialPrimer\n",
    "            if reversePotentialPrimer not in primer_pool:\n",
    "                primer_pool[reversePotentialPrimer] = 1\n",
    "            else:\n",
    "                primer_pool[reversePotentialPrimer] = primer_pool[reversePotentialPrimer] + 1 \n",
    "\n",
    "###MseI - PstI PstI\n",
    "primer2_pool = {}\n",
    "for chr in variant_repo:\n",
    "    for SNP in variant_repo[chr]:\n",
    "        uniqueID = SNP[0]\n",
    "        SNPposition = int(SNP[1])\n",
    "        hundredAhead = reference_test[chr][SNPposition:(SNPposition+200)]\n",
    "        cuttingPos = hundredAhead.find(\"CTGCAG\")\n",
    "        if cuttingPos >= 16:\n",
    "            potentialPrimer = hundredAhead[(cuttingPos-16):cuttingPos]\n",
    "            #not reverse\n",
    "            reversePotentialPrimer = potentialPrimer\n",
    "            if reversePotentialPrimer not in primer2_pool:\n",
    "                primer2_pool[reversePotentialPrimer] = 1\n",
    "            else:\n",
    "                primer2_pool[reversePotentialPrimer] = primer2_pool[reversePotentialPrimer] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('dict.csv', 'w',newline = \"\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in primer_pool.items():\n",
    "#        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('dict_primer2.csv', 'w',newline = \"\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in primer2_pool.items():\n",
    "#        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "#For a given string(like a chromosome), find all hits\n",
    "#return a generator\n",
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub)\n",
    "\n",
    "#List all hits in the chromosome, and catach all possible combinations with expected size\n",
    "#the function is out-of-date because of overestimating number of amplicons\n",
    "def catch_fragment(chromosome,hits_list1, hits_list2):\n",
    "    validFragmentNum = 0\n",
    "    validSNP = 0\n",
    "    for hit1 in hits_list1:\n",
    "        for hit2 in hits_list2:\n",
    "            if((int(hit2) - int(hit1)) >100) and ((int(hit2) - int(hit1)) <250):\n",
    "                validFragmentNum = validFragmentNum + 1\n",
    "                validSNP = validSNP + SNP_inside(chromosome,hit1,hit2)\n",
    "    return [validFragmentNum,validSNP]\n",
    "\n",
    "def catch_fragment_large(chromosome,hits_list1, hits_list2):\n",
    "    validFragmentNum = 0\n",
    "    validSNP = 0\n",
    "    for hit1 in hits_list1:\n",
    "        for hit2 in hits_list2:\n",
    "            if((int(hit2) - int(hit1)) >249) and ((int(hit2) - int(hit1)) <1000):\n",
    "                validFragmentNum = validFragmentNum + 1\n",
    "                validSNP = validSNP + SNP_inside(chromosome,hit1,hit2)\n",
    "    return [validFragmentNum,validSNP]\n",
    "\n",
    "#count how many SNPs inside a given fragement inside the chromosome\n",
    "def SNP_inside(current_chromosome, current_hit1, current_hit2):\n",
    "    return len(variant_repo_no_ID[current_chromosome].intersection(range(current_hit1,current_hit2)))\n",
    "\n",
    "#return all SNPs inside a given fragement inside the chromosome \n",
    "def SNP_inside_with_name(current_chromosome, current_hit1, current_hit2):\n",
    "    return [variant_repo_no_ID[current_chromosome].intersection(range(current_hit1,current_hit2))]\n",
    "\n",
    "#PCR simulator\n",
    "#for a pair of given priemrs, report all hits' position\n",
    "#catch all fragments with 500 - 1000 bps.\n",
    "\n",
    "allChr = list(reference_test.keys())\n",
    "# def pcr_simulator(chr):\n",
    "#     validFragment = 0\n",
    "#     primer_one_hits = list(find_all(reference_test[chr],primer_one))\n",
    "#     primer_two_hits = list(find_all(reference_test[chr],primer_two))\n",
    "#     validFragment = validFragment + catch_fragment(primer_one_hits,primer_two_hits)\n",
    "#     del primer_one_hits\n",
    "#     del primer_two_hits\n",
    "#     return validFragment\n",
    "\n",
    "###Brute force is not too bad\n",
    "###Marker PstI and MseI\n",
    "#create a new method for brute force\n",
    "def pcr_simulator_para(primerPair):\n",
    "    primer_one = primerPair[0]\n",
    "    primer_two = primerPair[1]\n",
    "    validFragment = 0\n",
    "    validSNP = 0\n",
    "    validFragment_large = 0\n",
    "    validSNP_large = 0\n",
    "    \n",
    "    for chr in allChr:\n",
    "        primer_one_hits = list(find_all(reference_test[chr],primer_one))\n",
    "        primer_two_hits = list(find_all(reference_test[chr],primer_two))\n",
    "        frag_and_SNP = catch_fragment(chr,primer_one_hits,primer_two_hits)\n",
    "        validFragment = validFragment + frag_and_SNP[0]\n",
    "        validSNP = validSNP + frag_and_SNP[1]\n",
    "        \n",
    "        frag_and_SNP_large = catch_fragment_large(chr,primer_one_hits,primer_two_hits)\n",
    "        validFragment_large = validFragment_large + frag_and_SNP_large[0]\n",
    "        validSNP_large = validSNP_large + frag_and_SNP_large[1]\n",
    "        \n",
    "    return [primerPair[0],primer_pool[primerPair[0]],primerPair[1],primer2_pool[primerPair[1]],validFragment,validSNP,validFragment_large,validSNP_large]\n",
    "\n",
    "def pcr_simulator_para_for_site(primerPair):\n",
    "    primer_one = primerPair[0]\n",
    "    primer_two = primerPair[1]\n",
    "    validFragment = 0\n",
    "    validSNP = 0\n",
    "    validFragment_large = 0\n",
    "    validSNP_large = 0\n",
    "    \n",
    "    for chr in allChr:\n",
    "        primer_one_hits = list(find_all(reference_test[chr],primer_one))\n",
    "        primer_two_hits = list(find_all(reference_test[chr],primer_two))\n",
    "        frag_and_SNP = catch_fragment(chr,primer_one_hits,primer_two_hits)\n",
    "        validFragment = validFragment + frag_and_SNP[0]\n",
    "        validSNP = validSNP + frag_and_SNP[1]\n",
    "        \n",
    "        frag_and_SNP_large = catch_fragment_large(chr,primer_one_hits,primer_two_hits)\n",
    "        validFragment_large = validFragment_large + frag_and_SNP_large[0]\n",
    "        validSNP_large = validSNP_large + frag_and_SNP_large[1]\n",
    "        \n",
    "    return [primerPair[0],primerPair[1],validFragment,validSNP,validFragment_large,validSNP_large]\n",
    "\n",
    "def pcr_simulator_para_two(primerPair):\n",
    "    primer_result = pcr_simulator_para(primerPair)\n",
    "    #Add enzyme site  CTGCAG or TTAA\n",
    "    primerPairSite = [primerPair[0]+ enzyme1, primerPair[1] + enzyme2]\n",
    "    primer_with_site_result = pcr_simulator_para_for_site(primerPairSite)\n",
    "    return [primer_result,primer_with_site_result]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#Return a list with all amplicons, which is a list contain all info about it.\n",
    "def one_primer_detail(primerPair):\n",
    "    ampliconHolder = []\n",
    "    for chr in allChr:\n",
    "        primer1Hits = list(find_all(reference_test[chr],primerPair[0]))\n",
    "        primer2Hits = list(find_all(reference_test[chr],primerPair[1]))\n",
    "        iterPrimer1Hits = iter(primer1Hits)\n",
    "        iterPrimer2Hits = iter(primer2Hits)\n",
    "        primer1First = next(iterPrimer1Hits,False)\n",
    "        primer1Second = next(iterPrimer1Hits,False)\n",
    "        primer2First = next(iterPrimer2Hits,False)\n",
    "        primer2Second = next(iterPrimer2Hits,False)\n",
    "        while(primer1Second and primer2Second): ##check iterator hasNext()\n",
    "            if primer2First < primer1First:   \n",
    "                ## ______P1_______P1____\n",
    "                ##___P2_______________\n",
    "                primer2First = primer2Second\n",
    "                primer2Second = next(iterPrimer2Hits,False)\n",
    "            elif primer1Second < primer2First:\n",
    "                ## ______P1_______P1____\n",
    "                ##____________________P2______\n",
    "                primer1First = primer1Second\n",
    "                primer1Second = next(iterPrimer1Hits,False)\n",
    "            else:\n",
    "                ##_______P1________P1___\n",
    "                ##__________P2__________\n",
    "                if (primer2First - primer1First) < 5000: ##too long fragment may not be real and memory-consuming\n",
    "                    anAmplicon=[primer1First,primer2First,chr,reference_test[chr][primer1First:primer2First], primer2First - primer1First,SNP_inside(chr,primer1First,primer2First),SNP_inside_with_name(chr,primer1First,primer2First)]\n",
    "                    if (primer2First - primer1First) > 120: #extract 120 or less bp part of an amplicon\n",
    "                        anAmplicon.append(reference_test[chr][primer1First:(primer1First+120)])\n",
    "                    else:\n",
    "                        anAmplicon.append(reference_test[chr][primer1First:primer2First])\n",
    "                    ampliconHolder.append(anAmplicon)\n",
    "                primer1First = primer1Second\n",
    "                primer1Second = next(iterPrimer1Hits,False)\n",
    "                primer2First = primer2Second\n",
    "                primer2Second = next(iterPrimer2Hits,False)\n",
    "    return ampliconHolder\n",
    "\n",
    "\n",
    "#This function counts distributions of amplicons on each chromosome\n",
    "#This function obtained amount of information about one primer pair.\n",
    "def one_primer_amplicon_distribution(primerPair):\n",
    "    ampliconInPCR = one_primer_detail(primerPair)\n",
    "    ampliconByChr = {}\n",
    "    for amplicon in ampliconInPCR:\n",
    "        ampliconSample = {\"1A\":0,\"1B\":0,\"1D\":0,\n",
    "                         \"2A\":0,\"2B\":0,\"2D\":0,\n",
    "                         \"3A\":0,\"3B\":0,\"3D\":0,\n",
    "                         \"4A\":0,\"4B\":0,\"4D\":0,\n",
    "                         \"5A\":0,\"5B\":0,\"5D\":0,\n",
    "                         \"6A\":0,\"6B\":0,\"6D\":0,\n",
    "                         \"7A\":0,\"7B\":0,\"7D\":0}\n",
    "        if amplicon[3] not in ampliconByChr:\n",
    "            ampliconByChr[amplicon[3]] = ampliconSample\n",
    "            ampliconByChr[amplicon[3]][amplicon[2]] = ampliconByChr[amplicon[3]][amplicon[2]] + 1\n",
    "        else:\n",
    "            ampliconByChr[amplicon[3]][amplicon[2]] = ampliconByChr[amplicon[3]][amplicon[2]] + 1\n",
    "    return ampliconByChr\n",
    "\n",
    "def one_primer_amplicon_first120_distribution(primerPair):\n",
    "    ampliconInPCR = one_primer_detail(primerPair)\n",
    "    ampliconFirst120ByChr = {}\n",
    "    for amplicon in ampliconInPCR:\n",
    "        ampliconSample = {\"1A\":0,\"1B\":0,\"1D\":0,\n",
    "                         \"2A\":0,\"2B\":0,\"2D\":0,\n",
    "                         \"3A\":0,\"3B\":0,\"3D\":0,\n",
    "                         \"4A\":0,\"4B\":0,\"4D\":0,\n",
    "                         \"5A\":0,\"5B\":0,\"5D\":0,\n",
    "                         \"6A\":0,\"6B\":0,\"6D\":0,\n",
    "                         \"7A\":0,\"7B\":0,\"7D\":0}\n",
    "        if amplicon[-1] not in ampliconFirst120ByChr:\n",
    "            ampliconFirst120ByChr[amplicon[-1]] = ampliconSample\n",
    "            ampliconFirst120ByChr[amplicon[-1]][amplicon[2]] = ampliconFirst120ByChr[amplicon[-1]][amplicon[2]] + 1\n",
    "        else:\n",
    "            ampliconFirst120ByChr[amplicon[-1]][amplicon[2]] = ampliconFirst120ByChr[amplicon[-1]][amplicon[2]] + 1\n",
    "    return ampliconFirst120ByChr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The ampliconByChr is stored in a dictionary. The function below is to insert the dictionary to each line.\n",
    "def one_primer_merge_detail_distribution(primerPair):\n",
    "    ampliconInPCR = one_primer_detail(primerPair)\n",
    "    ampliconByChr = one_primer_amplicon_distribution(primerPair)\n",
    "    ampliconFirst120ByChr = one_primer_amplicon_first120_distribution(primerPair)\n",
    "    for amplicon in ampliconInPCR:\n",
    "        amplicon.insert(3,ampliconByChr[amplicon[3]])\n",
    "        amplicon.append(ampliconFirst120ByChr[amplicon[-1]])\n",
    "    return ampliconInPCR\n",
    "\n",
    "from collections import Counter\n",
    "def compute_mode(numbers):\n",
    "    modes = []\n",
    "    counts = Counter(numbers)\n",
    "    maxCount = max(counts.values())\n",
    "    for num,count in counts.items():\n",
    "        if count==maxCount:\n",
    "            modes.append(num)\n",
    "    return modes\n",
    "\n",
    "\n",
    "def one_primer_summary(primerPair):\n",
    "    onePrimerPair = one_primer_merge_detail_distribution(primerPair)\n",
    "    aGenomeHits,bGenomeHits,dGenomeHits = 0,0,0\n",
    "    totalSNP = 0\n",
    "    uniqueAmplicon = 0\n",
    "    uniqueAmpliconFirst120 = 0\n",
    "    totalAmplicon = len(onePrimerPair)\n",
    "    if totalAmplicon > 1:\n",
    "        sizeMode = 0\n",
    "        sizeList = []\n",
    "        for eachAmpliconInfo in onePrimerPair:\n",
    "            aGenomeHits = aGenomeHits + sum([eachAmpliconInfo[3][\"1A\"],eachAmpliconInfo[3][\"2A\"],eachAmpliconInfo[3][\"3A\"],eachAmpliconInfo[3][\"4A\"],eachAmpliconInfo[3][\"5A\"],eachAmpliconInfo[3][\"6A\"],eachAmpliconInfo[3][\"7A\"]])\n",
    "            bGenomeHits = bGenomeHits + sum([eachAmpliconInfo[3][\"1B\"],eachAmpliconInfo[3][\"2B\"],eachAmpliconInfo[3][\"3B\"],eachAmpliconInfo[3][\"4B\"],eachAmpliconInfo[3][\"5B\"],eachAmpliconInfo[3][\"6B\"],eachAmpliconInfo[3][\"7B\"]])\n",
    "            dGenomeHits = dGenomeHits + sum([eachAmpliconInfo[3][\"1D\"],eachAmpliconInfo[3][\"2D\"],eachAmpliconInfo[3][\"3D\"],eachAmpliconInfo[3][\"4D\"],eachAmpliconInfo[3][\"5D\"],eachAmpliconInfo[3][\"6D\"],eachAmpliconInfo[3][\"7D\"]])\n",
    "            totalSNP = totalSNP + eachAmpliconInfo[6]\n",
    "            sizeList.append(eachAmpliconInfo[5])\n",
    "            allHits = sum(eachAmpliconInfo[3].values())\n",
    "            if allHits == 1: uniqueAmplicon = uniqueAmplicon + 1\n",
    "            if sum(eachAmpliconInfo[-1].values()) == 1: uniqueAmpliconFirst120 = uniqueAmpliconFirst120 + 1\n",
    "        uniqueRatio = uniqueAmplicon/totalAmplicon\n",
    "        sizeMode = compute_mode(sizeList)\n",
    "        return [primerPair[0],primerPair[1],totalAmplicon,aGenomeHits,bGenomeHits,dGenomeHits,totalSNP,uniqueAmplicon,uniqueRatio,uniqueAmpliconFirst120,uniqueAmpliconFirst120/totalAmplicon,sizeMode]\n",
    "    else:\n",
    "        return [primerPair[0],primerPair[1],0]\n",
    "#     ['TAGGCGAGTACTTGG',\n",
    "#  'ACTCGGTAGGATTTTT',\n",
    "#  2356,\n",
    "#  29535,\n",
    "#  45643,\n",
    "#  150,\n",
    "#  1476174135,\n",
    "#  1532,\n",
    "#  0.6502546689303905,\n",
    "#  0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPoentialPrimer = [] \n",
    "for primer1, occur1 in primer_pool.items():\n",
    "    if occur1 >600:\n",
    "        for primer2, occur2 in primer2_pool.items():\n",
    "            if occur2 >1000 and primer2 != \"\":\n",
    "                allPoentialPrimer.append([primer1,primer2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allPoentialPrimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define enzyme site in pcr_simulator_para_two first\n",
    "enzyme1 = \"TTAA\"\n",
    "enzyme2 = \"CTGCAG\"\n",
    "with Pool(12) as p:\n",
    "    potentialPrimerResult = p.map(pcr_simulator_para_two,allPoentialPrimer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('potentialPrimerMse_Pst_16_15_everything.csv', 'w',newline = \"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for value in potentialPrimerResult:\n",
    "       writer.writerow(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalPrimerpPair1 = one_primer_merge_detail_distribution([\"TAGGCGAGTACTTGG\",\"ACTCGGTAGGATTTTT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[621985061,\n",
       " 621985187,\n",
       " '5B',\n",
       " {'1A': 0,\n",
       "  '1B': 0,\n",
       "  '1D': 0,\n",
       "  '2A': 0,\n",
       "  '2B': 0,\n",
       "  '2D': 0,\n",
       "  '3A': 0,\n",
       "  '3B': 0,\n",
       "  '3D': 0,\n",
       "  '4A': 0,\n",
       "  '4B': 0,\n",
       "  '4D': 0,\n",
       "  '5A': 0,\n",
       "  '5B': 1,\n",
       "  '5D': 0,\n",
       "  '6A': 0,\n",
       "  '6B': 0,\n",
       "  '6D': 0,\n",
       "  '7A': 0,\n",
       "  '7B': 0,\n",
       "  '7D': 0},\n",
       " 'TAGGCGAGTACTTGGACTGCAGCTAAGCCTCCGAGTGGGAGGCTGGCTCACCACTCGGTAGGATTTTAAACACTTAGGAGAGTACTTGGACTGTAGCTAAGCCTCCGAGTGGGAGGATTGCTCTCC',\n",
       " 126,\n",
       " 0,\n",
       " [set()],\n",
       " 'TAGGCGAGTACTTGGACTGCAGCTAAGCCTCCGAGTGGGAGGCTGGCTCACCACTCGGTAGGATTTTAAACACTTAGGAGAGTACTTGGACTGTAGCTAAGCCTCCGAGTGGGAGGATTG',\n",
       " {'1A': 0,\n",
       "  '1B': 0,\n",
       "  '1D': 0,\n",
       "  '2A': 0,\n",
       "  '2B': 0,\n",
       "  '2D': 0,\n",
       "  '3A': 0,\n",
       "  '3B': 0,\n",
       "  '3D': 0,\n",
       "  '4A': 0,\n",
       "  '4B': 0,\n",
       "  '4D': 0,\n",
       "  '5A': 0,\n",
       "  '5B': 1,\n",
       "  '5D': 0,\n",
       "  '6A': 0,\n",
       "  '6B': 0,\n",
       "  '6D': 0,\n",
       "  '7A': 0,\n",
       "  '7B': 0,\n",
       "  '7D': 0}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalPrimerpPair1[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finalPrimerpPair1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a52967b901a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maGenomeHits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbGenomeHits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdGenomeHits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0meachAmpliconInfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinalPrimerpPair1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meachAmpliconInfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#aGenomeHits = aGenomeHits + sum([eachAmpliconInfo[3][\"1A\"],eachAmpliconInfo[3][\"2A\"],eachAmpliconInfo[3][\"3A\"],eachAmpliconInfo[3][\"4A\"],eachAmpliconInfo[3][\"5A\"],eachAmpliconInfo[3][\"6A\"],eachAmpliconInfo[3][\"7A\"]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#bGenomeHits = bGenomeHits + sum([eachAmpliconInfo[3][\"1B\"],eachAmpliconInfo[3][\"2B\"],eachAmpliconInfo[3][\"3B\"],eachAmpliconInfo[3][\"4B\"],eachAmpliconInfo[3][\"5B\"],eachAmpliconInfo[3][\"6B\"],eachAmpliconInfo[3][\"7B\"]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'finalPrimerpPair1' is not defined"
     ]
    }
   ],
   "source": [
    "aGenomeHits,bGenomeHits,dGenomeHits = 0,0,0\n",
    "for eachAmpliconInfo in finalPrimerpPair1:\n",
    "    print(eachAmpliconInfo[3].values())\n",
    "        #aGenomeHits = aGenomeHits + sum([eachAmpliconInfo[3][\"1A\"],eachAmpliconInfo[3][\"2A\"],eachAmpliconInfo[3][\"3A\"],eachAmpliconInfo[3][\"4A\"],eachAmpliconInfo[3][\"5A\"],eachAmpliconInfo[3][\"6A\"],eachAmpliconInfo[3][\"7A\"]])\n",
    "        #bGenomeHits = bGenomeHits + sum([eachAmpliconInfo[3][\"1B\"],eachAmpliconInfo[3][\"2B\"],eachAmpliconInfo[3][\"3B\"],eachAmpliconInfo[3][\"4B\"],eachAmpliconInfo[3][\"5B\"],eachAmpliconInfo[3][\"6B\"],eachAmpliconInfo[3][\"7B\"]])\n",
    "        #dGenomeHits = dGenomeHits + sum([eachAmpliconInfo[3][\"1D\"],eachAmpliconInfo[3][\"2D\"],eachAmpliconInfo[3][\"3D\"],eachAmpliconInfo[3][\"4D\"],eachAmpliconInfo[3][\"5D\"],eachAmpliconInfo[3][\"6D\"],eachAmpliconInfo[3][\"7D\"]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in finalPrimerpPair1 if((x[3] < 300) and (x[3]>50)) and x[4] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSets = []\n",
    "with open(\"Adj_primersets.csv\") as testSetFile:\n",
    "    testSetsAllLine = testSetFile.readlines()\n",
    "    for line in testSetsAllLine:\n",
    "        testSets.append(line.strip().upper().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18', 'GCGAGTACTGGACTGCAG', 'ACTCGGTAGGATTTTTTAA']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSets[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSetInfo = []\n",
    "for primerPair in testSets:\n",
    "    onePrimerInfo = one_primer_merge_detail_distribution(primerPair[1:])\n",
    "    testSetInfo.append([x for x in onePrimerInfo if((x[5] < 5000) and (x[5]>25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testSetInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-a304ccee76ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0monerow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0monerow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"4A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"5A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"6A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"7A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0monerow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"4B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"5B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"6B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"7B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0monerow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"4D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"5D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"6D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"7D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "for i in range(0,22):\n",
    "    fileName = \"final_each_primer_distribution_set_\" + str(i) + \".csv\"\n",
    "    with open(fileName, 'w',newline = \"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"start\",\"end\",\"chr\",\"length\",\"# of SNP\",\"pos of SNP, (set() means no SNP) \"])\n",
    "        for value in testSetInfo[i]:\n",
    "            onerow = [value[0],value[1],value[2]]\n",
    "            onerow.append(value[4])\n",
    "            onerow.append(value[5])\n",
    "            onerow.append(value[6])\n",
    "            onerow.append(value[7])\n",
    "            chrSeq = []\n",
    "            for key in value[3]:\n",
    "                onerow.append(value[3][key])\n",
    "                onerow.append(sum([value[3][\"1A\"],value[3][\"2A\"],value[3][\"3A\"],value[3][\"4A\"],value[3][\"5A\"],value[3][\"6A\"],value[3][\"7A\"]]))\n",
    "                onerow.append(sum([value[3][\"1B\"],value[3][\"2B\"],value[3][\"3B\"],value[3][\"4B\"],value[3][\"5B\"],value[3][\"6B\"],value[3][\"7B\"]]))\n",
    "                onerow.append(sum([value[3][\"1D\"],value[3][\"2D\"],value[3][\"3D\"],value[3][\"4D\"],value[3][\"5D\"],value[3][\"6D\"],value[3][\"7D\"]]))\n",
    "                onerow.append(sum(value[3].values()))\n",
    "                chrSeq.append(key)\n",
    "            writer.writerow(onerow)\n",
    "        chrSeq.append(\"A subgenome\")\n",
    "        chrSeq.append(\"B subgenome\")\n",
    "        chrSeq.append(\"D subgenome\")\n",
    "        chrSeq.append(\"sum of occurrances\")\n",
    "        writer.writerow(chrSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = one_primer_merge_detail_distribution([\"TAGGCGAGTACTTGG\",\"ACTCGGTAGGATTTTT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TAGGCGAGTACTTGG',\n",
       " 'ACTCGGTAGGATTTTT',\n",
       " 1596,\n",
       " 29435,\n",
       " 44985,\n",
       " 148,\n",
       " 498,\n",
       " 772,\n",
       " 0.48370927318295737,\n",
       " 717,\n",
       " 0.4492481203007519,\n",
       " [52]]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_primer_summary([\"TAGGCGAGTACTTGG\",\"ACTCGGTAGGATTTTT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Pool(12) as p:\n",
    "    potentialPrimerResult = p.map(one_primer_summary,allPoentialPrimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "fileName = \"potentialPrimerResultAug9.csv\"\n",
    "with open(fileName, 'w',newline = \"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for element in potentialPrimerResult:\n",
    "        \n",
    "        writer.writerow(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
